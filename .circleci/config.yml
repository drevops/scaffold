# CircleCI 2.0 configuration file.
#
# This configuration file uses the "docker" executor to run the Docker stack.
#
# A "runner" container, created from a specified container image, is used to
# checkout source code and run commands defined in this file. Application Docker
# containers defined in `docker-compose.yml` run on a *remote* Docker server
# controlled by CircleCI.
# The "runner" container uses Docker client to control the remote Docker server.
#;
#; Comments starting with '#;<' and '#;>' are internal Scaffold comments
#; and will be removed during installation or update of Scaffold.
version: '2.1'

aliases:
  #;< !PROVISION_USE_PROFILE
  # SSH key fingerprint to download the database.
  # Replace this key fingerprint with your own and remove this comment.
  - &db_ssh_fingerprint "56:f3:3f:51:c3:8f:b3:75:01:90:6e:26:48:e7:48:e1"
  #;> !PROVISION_USE_PROFILE

  # SSH key fingerprint to deploy code.
  # Replace this key fingerprint with your own and remove this comment.
  - &deploy_ssh_fingerprint "56:f3:3f:51:c3:8f:b3:75:01:90:6e:26:48:e7:48:e1"

  #;< !PROVISION_USE_PROFILE
  # Schedule to run nightly database build (to cache the database for the next day).
  - &nightly_db_schedule "0 18 * * *"
  #;> !PROVISION_USE_PROFILE

  #;< RENOVATEBOT
  # Specify the correct repository to prevent the bot from accessing all
  # repositories available via $RENOVATE_TOKEN.
  #;< SCAFFOLD_DEV
  - &renovatebot_repository 'drevops/scaffold-destination'
  #;> SCAFFOLD_DEV
  ##### - &renovatebot_repository 'your_org/your_site'
  # The schedule to run RenovateBot on. Defaults to running twice a day.
  - &renovatebot_schedule "5 11,23 * * *"
  # The author details to use for commits made by RenovateBot.
  - &renovatebot_git_author 'RenovateBot Self Hosted <renovatebot@your-site-url.example>'
  #;> RENOVATEBOT

  # Shared runner container configuration applied to each job.
  - &runner_config
    working_directory: &working_directory ~/project
    environment:
      #;< !PROVISION_USE_PROFILE
      DREVOPS_DB_DOWNLOAD_SSH_FINGERPRINT: *db_ssh_fingerprint
      #;> !PROVISION_USE_PROFILE
      DREVOPS_DEPLOY_SSH_FINGERPRINT: *deploy_ssh_fingerprint
    docker:
      # Using the 'runner' container where each job will be executed.
      # This container has all the necessary tools to run a dockerized environment.
      # @see https://github.com/drevops/ci-runner
      # @see https://hub.docker.com/repository/docker/drevops/ci-runner/tags?page=1&ordering=last_updated
      - image: drevops/ci-runner:24.4.0
        auth:
          username: ${DREVOPS_CONTAINER_REGISTRY_USER}
          password: ${DREVOPS_CONTAINER_REGISTRY_PASS}
        environment:
          # Set runner timezone to ensure that executed operations use correct timestamps.
          # @see https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
          TZ: "Australia/Melbourne"
          # Set runner terminal capabilities.
          TERM: xterm-256color
          #;< !PROVISION_USE_PROFILE
          # How often to refresh the cache of the DB dump. Refer to `date` command.
          DREVOPS_CI_DB_CACHE_TIMESTAMP: +%Y%m%d
          # Use previous database caches on this branch as a fallback if the above cache
          # does not match (for example, the cache is available only from the previous
          # day). If "no" is set, the cache will be rebuilt from scratch.
          DREVOPS_CI_DB_CACHE_FALLBACK: "yes"
          # Which branch to use as a source of DB caches.
          DREVOPS_CI_DB_CACHE_BRANCH: "develop"
          #;> !PROVISION_USE_PROFILE
          # Directory to store test results.
          DREVOPS_CI_TEST_RESULTS: &test_results /tmp/tests
          # Directory to store test artifacts.
          DREVOPS_CI_ARTIFACTS: &artifacts /tmp/artifacts
          # Directory to store code exported between jobs.
          DREVOPS_EXPORT_CODE_DIR: &drevops_build_export_dir /tmp/workspace/code
          # Directory to use for artifact deployments.
          DREVOPS_DEPLOY_ARTIFACT_SRC: *drevops_build_export_dir
          # Source code location for artifact deployments.
          DREVOPS_DEPLOY_ARTIFACT_ROOT: *working_directory
          # Report file location for artifact deployments.
          DREVOPS_DEPLOY_ARTIFACT_LOG: /tmp/artifacts/deployment_log.txt
          # Check only minimal stack requirements.
          DREVOPS_DOCTOR_CHECK_MINIMAL: 1
    # CI runner resource class.
    # @see https://circleci.com/docs/2.0/configuration-reference/#resource_class
    # Change to 'large' for faster builds.
    resource_class: medium

  # Set up remote Docker.
  - &step_setup_remote_docker
    setup_remote_docker:
      # Docker Layer Caching allows to significantly speed up builds by caching
      # images built during previous runs.
      # @see https://circleci.com/docs/2.0/docker-layer-caching/
      docker_layer_caching: false
      version: default

  # Set up container network.
  - &step_setup_container_network
    run: docker network prune -f >/dev/null 2>&1 && docker network inspect amazeeio-network >/dev/null 2>&1 || docker network create amazeeio-network >/dev/null 2>&1 || true

  # Process the codebase to be run in CI environment.
  - &step_process_codebase_for_ci
    run:
      name: Process codebase to run in CI
      command: |
        find . -name "docker-compose.yml" -print0 | xargs -0 -I {} sh -c "sed -i -e ''/###/d'' {} && sed -i -e ''s/##//'' {}"
        mkdir -p /tmp/workspace/code

################################################################################
# JOBS
################################################################################

jobs:
  #;< !PROVISION_USE_PROFILE
  # Database handling is a first step of the build.
  # - $DREVOPS_CI_DB_CACHE_TIMESTAMP is used to determine if a fresh DB dump
  #   should be downloaded for the current build. Usually, a daily database dump
  #   is sufficient for development activities.
  # - $DREVOPS_CI_DB_CACHE_FALLBACK is used if the cache did not match $DREVOPS_CI_DB_CACHE_TIMESTAMP.
  #   This allows to rely on the cache from the previous days within the same branch.
  database: &job-database
    <<: *runner_config
    steps:
      - attach_workspace:
          at: /tmp/workspace

      - add_ssh_keys:
          fingerprints:
            - *db_ssh_fingerprint

      - checkout
      - *step_process_codebase_for_ci
      - *step_setup_remote_docker
      - *step_setup_container_network

      - run:
          name: Create cache keys for database caching as files
          command: |
            echo "${DREVOPS_CI_DB_CACHE_BRANCH}" | tee /tmp/db_cache_branch
            echo "${DREVOPS_CI_DB_CACHE_FALLBACK/no/${CIRCLE_BUILD_NUM}}" | tee /tmp/db_cache_fallback
            echo "$(date ${DREVOPS_CI_DB_CACHE_TIMESTAMP})" | tee /tmp/db_cache_timestamp
            echo "yes" | tee /tmp/db_cache_fallback_yes
            echo 'v1.21.0-db10-{{ checksum "/tmp/db_cache_branch" }}-{{ checksum "/tmp/db_cache_fallback" }}-{{ checksum "/tmp/db_cache_timestamp" }}'

      - restore_cache:
          keys:
            # Restore DB cache based on the cache strategy set by the cache keys below.
            # @see https://circleci.com/docs/2.0/caching/#restoring-cache
            # Change 'v1' to 'v2', 'v3' etc., commit and push to force cache reset.
            # Lookup cache based on the default branch and a timestamp. Allows
            # to use cache from the very first build on the day (sanitized database dump, for example).
            - v1.21.0-db10-{{ checksum "/tmp/db_cache_branch" }}-{{ checksum "/tmp/db_cache_fallback" }}-{{ checksum "/tmp/db_cache_timestamp" }}
            # Fallback to caching by default branch name only. Allows to use
            # cache from the branch build on the previous day.
            - v1.21.0-db10-{{ checksum "/tmp/db_cache_branch" }}-{{ checksum "/tmp/db_cache_fallback" }}-

      - run:
          name: Download DB
          command: DREVOPS_DB_DOWNLOAD_SEMAPHORE=/tmp/download-db-success ./scripts/drevops/download-db.sh
          no_output_timeout: 30m

      # Execute commands after database download script finished: if the
      # DB dump was downloaded - build the site (to ensure that the DB dump
      # is valid) and export the DB using selected method (to support
      # "file-to-image" or "image-to-file" conversions).
      # Note that configuration changes and the DB updates are not applied, so
      # the database will be cached in the same state as downloaded.
      - run:
          name: Export DB after download
          command: |
            [ ! -f /tmp/download-db-success ] && echo "==> Database download semaphore file is missing. DB export will not proceed." && exit 0
            ./scripts/drevops/login-container-registry.sh
            docker compose up -d && sleep 15
            docker compose exec cli mkdir -p .data && docker compose cp -L .data/db.sql cli:/app/.data/db.sql || true
            docker compose exec $(env | cut -f1 -d= | sed 's/^/-e /') -T cli bash -c "DREVOPS_PROVISION_POST_OPERATIONS_SKIP=1 ./scripts/drevops/provision.sh"
            grep -q ^DREVOPS_DB_IMAGE .env && rm .data/db.sql || true
            ./scripts/drevops/export-db.sh db.sql
          no_output_timeout: 30m

      - save_cache:
          # Save cache per default branch and the timestamp.
          # The cache will not be saved if it already exists.
          # Note that the cache fallback flag is enabled for this case in order
          # to save cache even if the fallback is not used when restoring it.
          key: v1.21.0-db10-{{ checksum "/tmp/db_cache_branch" }}-{{ checksum "/tmp/db_cache_fallback_yes" }}-{{ checksum "/tmp/db_cache_timestamp" }}
          paths:
            - /root/project/.data

  # Nightly database job. Same as above, but with additional variables set.
  database-nightly:
    <<: *job-database
    environment:
      DREVOPS_DB_DOWNLOAD_SSH_FINGERPRINT: *db_ssh_fingerprint
      DREVOPS_DEPLOY_SSH_FINGERPRINT: *deploy_ssh_fingerprint
      # Enforce fresh DB build (do not rely on fallback caches).
      DREVOPS_CI_DB_CACHE_FALLBACK: 'no'
      # Always use fresh base image for the database (if database-in-image storage is used).
      DREVOPS_DB_IMAGE_BASE: drevops/mariadb-drupal-data:24.4.0
      # Deploy container image (if database-in-image storage is used).
      DREVOPS_EXPORT_DB_CONTAINER_REGISTRY_DEPLOY_PROCEED: 1
  #;> !PROVISION_USE_PROFILE

  # Build and test is a second step of the build. The testing is performed
  # within the same job to save time on provisioning during the job.
  build: &job_build
    <<: *runner_config
    parallelism: 2
    steps:
      - attach_workspace:
          at: /tmp/workspace

      - checkout
      - *step_process_codebase_for_ci
      - *step_setup_remote_docker
      - *step_setup_container_network

      #;< !PROVISION_USE_PROFILE
      - run:
          name: Set cache keys for database caching
          command: |
            echo "${DREVOPS_CI_DB_CACHE_BRANCH}" | tee /tmp/db_cache_branch
            echo "yes" | tee /tmp/db_cache_fallback_yes
            echo "$(date ${DREVOPS_CI_DB_CACHE_TIMESTAMP})" | tee /tmp/db_cache_timestamp

      - restore_cache:
          keys:
            # Use cached artifacts from previous builds of this branch.
            # @see https://circleci.com/docs/2.0/caching/#restoring-cache
            - v1.21.0-db10-{{ checksum "/tmp/db_cache_branch" }}-{{ checksum "/tmp/db_cache_fallback_yes" }}-{{ checksum "/tmp/db_cache_timestamp" }}
            - v1.21.0-db10-{{ checksum "/tmp/db_cache_branch" }}-{{ checksum "/tmp/db_cache_fallback_yes" }}-
      #;> !PROVISION_USE_PROFILE

      - run:
          name: Lint Dockerfiles with Hadolint
          command: |
            for file in $(find . -name 'Dockerfile' -o -name '*.dockerfile'); do
              echo "Linting ${file}" && cat "${file}" | docker run --rm -i hadolint/hadolint || [ "${DREVOPS_CI_HADOLINT_IGNORE_FAILURE:-0}" -eq 1 ]
            done

      - run:
          name: Login to container registry
          command: ./scripts/drevops/login-container-registry.sh

      - run:
          name: Build stack
          command: docker compose up -d

      - run:
          name: Export built codebase
          command: |
            mkdir -p "${DREVOPS_EXPORT_CODE_DIR}"
            docker compose cp -L cli:"/app/." "${DREVOPS_EXPORT_CODE_DIR}"

      - run:
          name: Validate Composer configuration
          command: docker compose exec cli composer validate --strict || [ "${DREVOPS_CI_COMPOSER_VALIDATE_IGNORE_FAILURE:-0}" -eq 1 ]

      - run:
          name: Install development dependencies
          command: |
            docker compose exec $(env | cut -f1 -d= | sed 's/^/-e /') -T cli bash -c " \
              if [ -n \"${GITHUB_TOKEN:-}\" ]; then export COMPOSER_AUTH='{\"github-oauth\": {\"github.com\": \"${GITHUB_TOKEN-}\"}}'; fi && \
              COMPOSER_MEMORY_LIMIT=-1 composer --ansi install --prefer-dist"

      - run:
          name: Lint code with PHPCS
          command: docker compose exec -T cli vendor/bin/phpcs || [ "${DREVOPS_CI_PHPCS_IGNORE_FAILURE:-0}" -eq 1 ]

      - run:
          name: Lint code with PHPStan
          command: docker compose exec -T cli vendor/bin/phpstan || [ "${DREVOPS_CI_PHPSTAN_IGNORE_FAILURE:-0}" -eq 1 ]

      - run:
          name: Lint code with Rector
          command: docker compose exec -T cli vendor/bin/rector --clear-cache --dry-run || [ "${DREVOPS_CI_RECTOR_IGNORE_FAILURE:-0}" -eq 1 ]

      - run:
          name: Lint code with PHPMD
          command: docker compose exec -T cli vendor/bin/phpmd . text phpmd.xml || [ "${DREVOPS_CI_PHPMD_IGNORE_FAILURE:-0}" -eq 1 ]

      - run:
          name: Lint code with Twig CS Fixer
          command: docker compose exec -T cli vendor/bin/twig-cs-fixer || [ "${DREVOPS_CI_TWIG_CS_FIXER_IGNORE_FAILURE:-0}" -eq 1 ]

      - run:
          name: Lint code with NPM linters
          command: docker compose exec -T cli bash -c "npm run --prefix \${DREVOPS_WEBROOT}/themes/custom/\${DRUPAL_THEME} lint" || [ "${DREVOPS_CI_NPM_LINT_IGNORE_FAILURE:-0}" -eq 1 ]

      - run:
          name: Provision site
          command: |
            if [ -f .data/db.sql ]; then
              docker compose exec cli mkdir -p .data
              docker compose cp -L .data/db.sql cli:/app/.data/db.sql
            fi
            docker compose exec $(env | cut -f1 -d= | sed 's/^/-e /') -T cli ./scripts/drevops/provision.sh
          no_output_timeout: 30m

      - run:
          name: Test with PHPUnit
          command: |
            XDEBUG_ENABLE=true docker compose up -d cli php nginx # Restart stack with XDEBUG enabled for coverage.
            docker compose exec -T -e XDEBUG_MODE=coverage cli vendor/bin/phpunit || [ "${DREVOPS_CI_PHPUNIT_IGNORE_FAILURE:-0}" -eq 1 ]
            docker compose up -d cli php nginx # Restart stack without XDEBUG enabled for coverage.

      - run:
          name: Test with Behat
          command: |
            if [ "${CIRCLE_NODE_TOTAL:-1}" -gt 1 ]; then export DREVOPS_CI_BEHAT_PROFILE="${DREVOPS_CI_BEHAT_PROFILE:-p${CIRCLE_NODE_INDEX}}"; fi
            echo "Running with ${DREVOPS_CI_BEHAT_PROFILE:-default} profile"
            docker compose exec -T cli php -d memory_limit=-1 vendor/bin/behat --colors --strict --profile="${DREVOPS_CI_BEHAT_PROFILE:-default}" || \
              docker compose exec -T cli php -d memory_limit=-1 vendor/bin/behat --colors --strict --rerun --profile="${DREVOPS_CI_BEHAT_PROFILE:-default}" || \
              [ "${DREVOPS_CI_BEHAT_IGNORE_FAILURE:-0}" -eq 1 ]
          no_output_timeout: 30m

      - run:
          name: Process test logs and artifacts
          command: |
            mkdir -p "${DREVOPS_CI_TEST_RESULTS}" "${DREVOPS_CI_ARTIFACTS}"
            if docker compose ps --services --filter "status=running" | grep -q cli && docker compose exec cli test -d /app/.logs; then
               docker compose cp cli:/app/.logs/. "${DREVOPS_CI_ARTIFACTS}/"
              if docker compose exec -T cli sh -c '[ -d /app/.logs/test_results/ ]'; then
                 docker compose cp cli:/app/.logs/test_results/. "${DREVOPS_CI_TEST_RESULTS}/"
              fi
            fi
          when: always

      - store_test_results:
          path: *test_results

      - store_artifacts:
          path: *artifacts

      - run:
          name: Upload code coverage reports to Codecov
          command: if [ -n "${CODECOV_TOKEN}" ] && [ -d /tmp/artifacts/coverage ]; then codecov -Z -s /tmp/artifacts/coverage; fi

      - persist_to_workspace:
          root: /tmp/workspace
          paths:
            - code

  #;< DEPLOYMENT
  # Deploy primary branches.
  deploy: &job_deploy
    <<: *runner_config
    steps:
      - attach_workspace:
          at: /tmp/workspace

      - add_ssh_keys:
          fingerprints:
            - *deploy_ssh_fingerprint

      - checkout
      - *step_process_codebase_for_ci

      - run:
          command: |
            DREVOPS_DEPLOY_BRANCH="${CIRCLE_BRANCH}" \
            DREVOPS_DEPLOY_PR="$(echo ${CIRCLE_PULL_REQUEST} | cut -d'/' -f 7)" \
            DREVOPS_DEPLOY_PR_HEAD=${CIRCLE_SHA1} \
            ./scripts/drevops/deploy.sh
          no_output_timeout: 30m

      - store_artifacts:
          path: *artifacts

  # Deploy tags.
  deploy-tags: &job-deploy-tags
    <<: *runner_config
    steps:
      - attach_workspace:
          at: /tmp/workspace

      - add_ssh_keys:
          fingerprints:
            - *deploy_ssh_fingerprint

      - checkout
      - *step_process_codebase_for_ci

      - run:
          command: DREVOPS_DEPLOY_MODE="tag" ./scripts/drevops/deploy.sh
          no_output_timeout: 30m

      - store_artifacts:
          path: *artifacts
  #;> DEPLOYMENT

  #;< RENOVATEBOT
  # Self-hosted RenovateBot.
  # Add RENOVATE_TOKEN as an environment variable with GitHub access token in UI.
  renovatebot-self-hosted:
    docker:
      - image: renovate/renovate:37.342.1
        environment:
          RENOVATE_PLATFORM: 'github'
          RENOVATE_AUTODISCOVER: false
          RENOVATE_DEPENDENCY_DASHBOARD: true
          RENOVATE_DEPENDENCY_DASHBOARD_TITLE: 'RenovateBot Dependency Dashboard (self-hosted)'
          RENOVATE_REPOSITORIES: *renovatebot_repository
          RENOVATE_GIT_AUTHOR: *renovatebot_git_author
          RENOVATE_DRY_RUN: false
          LOG_LEVEL: debug
    steps:
      - checkout
      - run: renovate-config-validator
      - run: renovate
  #;> RENOVATEBOT

  #;============================================================================
  #; Scaffold development section. Removed during Scaffold installation/update.
  #;============================================================================
  #;< SCAFFOLD_DEV
  #-----------------------------------------------------------------------------
  # Test suite for Scaffold.
  #-----------------------------------------------------------------------------

  # Run Scaffold tests after 'build' job to test CircleCI's configuration.
  scaffold-dev-test-ci-postbuild:
    <<: *runner_config
    steps:
      - checkout
      - *step_process_codebase_for_ci
      - *step_setup_remote_docker
      - *step_setup_container_network

      - run:
          name: Run CircleCI tests (long)
          command: SCAFFOLD_DEV_VOLUMES_MOUNTED=0 SCAFFOLD_DEV_TEST_COVERAGE_DIR=/tmp/artifacts/coverage .scaffold/tests/test.postbuild.sh

      - store_test_results:
          path: *test_results

      - store_artifacts:
          path: *artifacts

      - run:
          name: Upload code coverage reports to Codecov
          command: codecov -Z -s /tmp/artifacts/coverage

  #-----------------------------------------------------------------------------
  # Launching and testing databases stored within Docker data image.
  #-----------------------------------------------------------------------------
  #
  # Switching between "database in file" (DIF, mounted data volume) and
  # "database-in-image" (DIDI, data volume is a part of the image) is
  # done by providing the value of DREVOPS_DB_IMAGE environment variable,
  # which would be set in .env file for consumer projects.
  #
  # Also, the source of the database can be either file (downloaded from
  # remote location) or a previous version of the data image.
  #
  # This means that there should be the following tests for Scaffold
  # database-in-image workflow functionality:
  # 1. DB is file -> create data image -> cache data image and push it to registry -> build and test site
  # 2. DB is image -> create data image -> cache data image and push it to registry -> build and test site
  #
  # Since we need to have "database" job generic for consumer sites and any
  # logic is controlled within DrevOps scripts, we have to create additional
  # test jobs below and run them as a part of the CI system for Scaffold itself.
  #
  # Job to test creation of the image from DB dump file when using
  # DREVOPS_DB_IMAGE workflow.
  scaffold-dev-didi-database-fi:
    <<: *job-database
    environment:
      DREVOPS_DB_DOWNLOAD_SOURCE: curl
      DREVOPS_DB_DOWNLOAD_FORCE: 1
      # Use container image database storage despite that the file is coming
      # from CURL - this is to make sure that image is exported into cache
      # to be used between jobs. Note that in consumer project .env file would
      # have DREVOPS_DB_IMAGE variable set and this environment variable
      # would not be required.
      #
      # Note that here and below we are using "destination" demo image - this
      # is to allow updating of this image from CI tests without jeopardizing
      # main demo image.
      DREVOPS_DB_IMAGE: drevops/drevops-mariadb-drupal-data-demo-destination-10.x
      # Use a separate tag to make sure that pushed image does not affect
      # other tests (pushing broken image as 'latest' would fail other tests).
      DREVOPS_DEPLOY_CONTAINER_REGISTRY_IMAGE_TAG: scaffold-dev-didi-database-fi
      # Also, use this job to test pushing of the DB image to the container
      # registry to replicate what database-nightly job would do.
      DREVOPS_EXPORT_DB_CONTAINER_REGISTRY_DEPLOY_PROCEED: 1
      # Use custom cache key for this workflow to make sure that caches from
      # the main workflow are separated from this one.
      DREVOPS_CI_DB_CACHE_BRANCH: scaffold-dev-didi-fi

  # Job to test creation of the image from the previous version of the image
  # when using database-in-image workflow.
  scaffold-dev-database-ii:
    <<: *job-database
    environment:
      DREVOPS_DB_DOWNLOAD_SOURCE: DREVOPS_CONTAINER_REGISTRY
      DREVOPS_DB_DOWNLOAD_FORCE: 1
      DREVOPS_DB_IMAGE: drevops/drevops-mariadb-drupal-data-demo-destination-10.x
      DREVOPS_DEPLOY_CONTAINER_REGISTRY_IMAGE_TAG: scaffold-dev-database-ii
      # Also, use this job to test pushing of the DB image to the container
      # registry so replicate what database-nightly job would do.
      DREVOPS_EXPORT_DB_CONTAINER_REGISTRY_DEPLOY_PROCEED: 1
      # Use custom cache key for this workflow to make sure that caches from
      # the main workflow are separated from this one.
      DREVOPS_CI_DB_CACHE_BRANCH: scaffold-dev-didi-ii

  # Job to test build of the image from the previous stage of the image when
  # using database-in-image workflow. Overwriting just the DREVOPS_DB_IMAGE
  # variable should change the storage mechanisms, but preserve application-level
  # stack operation.
  scaffold-dev-didi-build-fi:
    <<: *job_build
    environment:
      DREVOPS_DB_IMAGE: drevops/drevops-mariadb-drupal-data-demo-destination-10.x:drevops_dev_didi_database_fi
      # Use custom cache key for this workflow to make sure that caches from
      # the main workflow are separated from this one.
      DREVOPS_CI_DB_CACHE_BRANCH: scaffold-dev-didi-fi

  scaffold-dev-didi-build-ii:
    <<: *job_build
    environment:
      DREVOPS_DB_IMAGE: drevops/drevops-mariadb-drupal-data-demo-destination-10.x:drevops_dev_database_ii
      # Use custom cache key for this workflow to make sure that caches from
      # the main workflow are separated from this one.
      DREVOPS_CI_DB_CACHE_BRANCH: scaffold-dev-didi-ii
  #=============================================================================
  #;> SCAFFOLD_DEV

################################################################################
# WORKFLOWS
################################################################################

workflows:
  version: 2
  # Commit workflow. Runs for every commit push to the remote repository.
  commit:
    jobs:
      #;< !PROVISION_USE_PROFILE
      - database:
          filters:
            tags:
              only: /.*/
      #;> !PROVISION_USE_PROFILE
      - build:
          #;< !PROVISION_USE_PROFILE
          requires:
            - database
          #;> !PROVISION_USE_PROFILE
          filters:
            tags:
              only: /.*/
      #;< DEPLOYMENT
      - deploy:
          requires:
            - build
          filters:
            branches:
              # Allowed branches:
              # - main, master, develop, ci, cisomething
              # - deps/*
              # - feature/description, feature/123-description
              # - release/123.456.789, release/123.456.789-rc.123 (per https://semver.org/)
              # - release/2023-04-17, release/2023-04-17.123 (date-based)
              # - hotfix/123.456.789, hotfix/123.456.789-rc.1213 (per https://semver.org/)
              # - hotfix/2023-04-17, hotfix/2023-04-17.123 (date-based)
              only: /^(main|master|develop)$|^feature\/[a-zA-Z0-9\-\.\,_]+$|^ci.*|^deps\/.*|^(release|hotfix)\/[0-9]+(\.[0-9]+){2}(-rc\.[0-9]+)?$|^(release|hotfix)\/[0-9]{4}-[0-9]{2}-[0-9]{2}(\.[0-9]+)?$/
            tags:
              ignore: /.*/
      - deploy-tags:
          requires:
            - build
          filters:
            branches:
              ignore: /.*/
            tags:
              # Allowed tags:
              # - 123.456.789, 123.456.789-rc.123 (per https://semver.org/)
              # - 2023-04-17, 2023-04-17.123 (date-based)
              only: /^[0-9]+(\.[0-9]+){2}(-rc\.[0-9]+)?$|^[0-9]{4}-[0-9]{2}-[0-9]{2}(\.[0-9]+)?$/
      #;> DEPLOYMENT

  #;============================================================================
  #; Scaffold development section. Removed during Scaffold installation/update.
  #;============================================================================
  #;
  #;< SCAFFOLD_DEV
  # Run functional tests for Scaffold.
  # Note that these jobs must run within the "commit" workflow, because they
  # depend on the "build" job.
      # Run tests after 'build' job.
      - scaffold-dev-test-ci-postbuild:
          requires:
            - build
          filters:
            tags:
              only: /.*/

  # Test workflow to test DREVOPS_DB_IMAGE workflow for DB from file.
  scaffold-dev-didi-fi:
    jobs:
      - scaffold-dev-didi-database-fi
      - scaffold-dev-didi-build-fi:
          requires:
            - scaffold-dev-didi-database-fi

  # Test workflow to test DREVOPS_DB_IMAGE workflow for DB from the container registry.
  scaffold-dev-didi-ii:
    jobs:
      - scaffold-dev-database-ii
      - scaffold-dev-didi-build-ii:
          requires:
            - scaffold-dev-database-ii
  #=============================================================================
  #;> SCAFFOLD_DEV

  #;< !PROVISION_USE_PROFILE
  # Nightly database workflow runs overnight to capture fresh database and cache it.
  nightly-db:
    triggers:
      - schedule:
          cron: *nightly_db_schedule
          filters:
            branches:
              only:
                - develop
    jobs:
      - database-nightly
  #;> !PROVISION_USE_PROFILE

  #;< RENOVATEBOT
  # Self-hosted Renovatebot workflow.
  renovatebot-self-hosted:
    triggers:
      - schedule:
          cron: *renovatebot_schedule
          filters:
            branches:
              only:
                - develop
    jobs:
      - renovatebot-self-hosted
  #;> RENOVATEBOT
